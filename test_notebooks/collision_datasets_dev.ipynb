{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7b59c-4c0d-4335-aae6-18f9254434c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchlensmaker as tlm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pprint import pprint\n",
    "\n",
    "from torchlensmaker.testing.basic_transform import basic_transform\n",
    "from torchlensmaker.core.transforms import IdentityTransform\n",
    "from torchlensmaker.testing.collision_datasets import *\n",
    "from torchlensmaker.core.collision_detection import Newton, GD, LM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO test/view F and F grad of samples2D\n",
    "# F should be zero\n",
    "# F grad should be finite\n",
    "\n",
    "# new way to sample expected collide:\n",
    "# start from samples2D, pick random V, offset by random amount\n",
    "\n",
    "# analysis:\n",
    "# given dataset expected collide\n",
    "# list of algorithm\n",
    "# for each algorithm:\n",
    "# number of missing collisions\n",
    "# distribution of number of iterations to converge\n",
    "\n",
    "def dataset_view(dataset, rays_length=100):\n",
    "    \"View a collision dataset testcase with tlmviewer\"\n",
    "\n",
    "    # TODO display points at P to see rays origins\n",
    "\n",
    "    scene = tlm.viewer.new_scene(\"2D\")\n",
    "    #scene[\"data\"].extend(tlm.viewer.render_collisions(all_points, all_normals))\n",
    "\n",
    "    rays_start = dataset.P - rays_length*dataset.V\n",
    "    rays_end = dataset.P + rays_length*dataset.V\n",
    "    scene[\"data\"].append(\n",
    "        tlm.viewer.render_rays(rays_start, rays_end, layer=0)\n",
    "    )\n",
    "\n",
    "    assert torch.all(torch.isfinite(dataset.P))\n",
    "    assert torch.all(torch.isfinite(dataset.V))\n",
    "\n",
    "    scene[\"data\"].append(tlm.viewer.render_surfaces([dataset.surface], [IdentityTransform(dim=2, dtype=dataset.surface.dtype)], dim=2))\n",
    "    scene[\"title\"] = dataset.name\n",
    "    tlm.viewer.ipython_display(scene)\n",
    "    #tlm.viewer.dump(scene, ndigits=2)\n",
    "\n",
    "\n",
    "\n",
    "def convergence_plot(dataset, algos):\n",
    "    \"Plot convergence of collision detection for multiple algorithms\"\n",
    "\n",
    "    surface = dataset.surface\n",
    "    P, V = dataset.P, dataset.V\n",
    "\n",
    "    # move rays by a tiny bit, to avoid t=0 local minimum\n",
    "    # that happens with constructed datasets\n",
    "    # TODO augment dataset with different shifts\n",
    "    #P, V = move_rays(P, V, 0.)\n",
    "    \n",
    "    fig, axes = plt.subplots(len(algos), 1, figsize=(10, 3*len(algos)), layout=\"tight\", squeeze=False)\n",
    "\n",
    "    for i, algorithm in enumerate(algos):\n",
    "        axQ = axes.flat[i]\n",
    "\n",
    "        t_solve, t_history = algorithm(surface, P, V, init_t=torch.zeros((P.shape[0],)), history=True)\n",
    "        \n",
    "        # Reshape tensors for broadcasting\n",
    "        N, H = P.shape[0], t_history.shape[1]\n",
    "        P_expanded = P.unsqueeze(1)  # Shape: (N, 1, 2)\n",
    "        V_expanded = V.unsqueeze(1)  # Shape: (N, 1, 2)\n",
    "        t_history_expanded = t_history.unsqueeze(2)  # Shape: (N, H, 1)\n",
    "    \n",
    "        # Compute points_history\n",
    "        points_history = P_expanded + t_history_expanded * V_expanded  # Shape: (N, H, 2)\n",
    "    \n",
    "        assert t_history.shape == (N, H), (N, H)\n",
    "        assert points_history.shape == (N, H, 2)\n",
    "    \n",
    "        # plot Q(t)\n",
    "        for ray_index in range(t_history.shape[0]):\n",
    "            axQ.plot(range(t_history.shape[1]), surface.f(points_history[ray_index, :, :]))\n",
    "        \n",
    "        axQ.set_xlabel(\"iteration\")\n",
    "        axQ.set_ylabel(\"Q(t)\", rotation=0)\n",
    "        axQ.set_title(f\"{dataset.name} | {str(algorithm)}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def collision_statistics(surface, dataset, algos):\n",
    "    \"Compute and return collision statistics for a dataset and an algorithm\"\n",
    "\n",
    "    P, V = dataset.P, dataset.V\n",
    "\n",
    "    for i, algorithm in enumerate(algos):\n",
    "        t_solve, t_history = algorithm(surface, P, V, init_t=torch.zeros((P.shape[0],)), history=True)\n",
    "            \n",
    "        # Reshape tensors for broadcasting\n",
    "        N, H = P.shape[0], t_history.shape[1]\n",
    "        P_expanded = P.unsqueeze(1)  # Shape: (N, 1, 2)\n",
    "        V_expanded = V.unsqueeze(1)  # Shape: (N, 1, 2)\n",
    "        t_history_expanded = t_history.unsqueeze(2)  # Shape: (N, H, 1)\n",
    "    \n",
    "        # Compute points_history\n",
    "        points_history = P_expanded + t_history_expanded * V_expanded  # Shape: (N, H, 2)\n",
    "    \n",
    "        assert t_history.shape == (N, H), (N, H)\n",
    "        assert points_history.shape == (N, H, 2)\n",
    "\n",
    "        # count number of collisions\n",
    "        local_points = points_history[:, -1, :]\n",
    "        residuals = surface.f(local_points)\n",
    "\n",
    "        tol = 1e-6\n",
    "        count = torch.sum(torch.abs(residuals) > tol).item()\n",
    "        error = torch.sqrt(torch.sum(residuals**2) / N).item()\n",
    "\n",
    "        print(f\"{str(algorithm): <20} error={error:.6f} ({count} misses)\")\n",
    "\n",
    "    return\n",
    "\n",
    "algorithms = [\n",
    "    Newton(0.8, max_iter=10, max_delta=10),\n",
    "    GD(0.1, max_iter=10, max_delta=10),\n",
    "    LM(1.0, max_iter=10, max_delta=10),\n",
    "]\n",
    "\n",
    "surface = Sphere(10, 10)\n",
    "\n",
    "generators = [\n",
    "    normal_rays(offset=3.0, N=25),\n",
    "    offset_rays(offset=-0.2, N=15),\n",
    "]\n",
    "\n",
    "for gen in generators:\n",
    "    dataset = gen(surface)\n",
    "\n",
    "    # tlmviewer view\n",
    "    dataset_view(dataset)\n",
    "\n",
    "    # statistics\n",
    "    collision_statistics(surface, dataset, algorithms)\n",
    "    \n",
    "    # convergence plots\n",
    "    fig = convergence_plot(dataset, algorithms)\n",
    "    plt.show(fig)\n",
    "\n",
    "# individual test:\n",
    "# 1 surface\n",
    "# 1 ray generator\n",
    "\n",
    "# batch test:\n",
    "# 1 surface\n",
    "# many ray generators\n",
    "\n",
    "# merge of all datasets\n",
    "#merged = merge_datasets(list(COLLISION_DATASET_REGISTRY.values()))\n",
    "#dataset_view(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f12c0-63a6-4b1a-b0ef-d65ee532c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchlensmaker.core.surfaces import Sphere\n",
    "\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "s = Sphere(10, 5)\n",
    "samples = s.samples2D_full(N=3, epsilon=0.)\n",
    "grad = normalize(s.f_grad(samples))\n",
    "\n",
    "print(samples)\n",
    "print(grad)\n",
    "\n",
    "samples[:, 1] <= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac508d-8d67-45a5-a39d-5a6b37f55356",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand((5, 2)).shape == (5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a5c9c-6ec6-42f2-986d-a51c640d3a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
